# ğŸ¾ VetLLM

**VetLLM** is a domain-specific large language model (LLM) fine-tuned on publicly available veterinary medical literature, including peer-reviewed journal articles and case studies. It is designed to answer questions related to veterinary science, diagnostics, treatments, and pet health.

### ğŸ§  Model Highlights
- **Base model**: [Mistral-7B](https://huggingface.co/mistralai/Mistral-7B-v0.1)
- **Fine-tuning**: Performed using [LoRA](https://arxiv.org/abs/2106.09685) adapters for efficiency
- **Training dataset**: 146M tokens of veterinary-focused text, curated from public scientific sources
- **Training infrastructure**: 8Ã— NVIDIA H100 GPUs on Google Cloud Platform (GCP)
- **Total training time**: 70 hours

---

ğŸ› ï¸ Setup
Create a virtual environment and install dependencies:

```bash
python3 -m venv venv
source venv/bin/activate
pip install --upgrade pip
pip install -r requirements.txt

```
ğŸ“ Project Structure

```base
VetLLM/
â”œâ”€â”€ vetllm.py                        # Training and inference script
â”œâ”€â”€ combined.txt                    # Raw training corpus
â”œâ”€â”€ results/                        # Checkpoints and logs
â”œâ”€â”€ finetuned-mistral7b-vet-lora/   # LoRA adapter output
â”œâ”€â”€ finetuned-mistral7b-vet-merged/ # Final merged model
â”œâ”€â”€ run.sh                          # Shell script for GCP automation
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```


ğŸ“œ License
This project uses publicly accessible veterinary articles. Verify licensing before commercial use or redistribution.
